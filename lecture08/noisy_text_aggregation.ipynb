{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226013ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install crowd-kit==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9939078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "from typing import Iterable, Tuple, List, Dict, Set\n",
    "from functools import lru_cache\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import nltk\n",
    "from tqdm.auto import tqdm\n",
    "from crowdkit.aggregation import ROVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc7ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir ./data\n",
    "# !wget https://raw.githubusercontent.com/vadim0912/MLIntro2022_Spring/main/lecture08/data/noisy_text_aggregation_* -P data/\n",
    "# !wget -r https://raw.githubusercontent.com/vadim0912/MLIntro2022_Spring/main/lecture08/data/audio -P data/audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e59615",
   "metadata": {},
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a39a5b",
   "metadata": {},
   "source": [
    "Дано:\n",
    "* три модели распознавания речи:\n",
    "    * `qnet`: [QuartzNet](https://arxiv.org/abs/1910.10261)\n",
    "    * `w2v`: [wav2vec XLS-R](https://arxiv.org/pdf/2111.09296.pdf)\n",
    "    * `w2v-tts`: тот же [wav2vec XLS-R](https://arxiv.org/pdf/2111.09296.pdf), но в дообучении использовались синтезированные (Text-To-Speech) данные\n",
    "   \n",
    "   \n",
    " * модели имеют разную структуру (QuartzNet — сверточная, wav2vec — Трансформер) и обучались на разных данных => из их предсказаний можно построить композицию, которая сильнее любого кандидата в отдельности\n",
    " * В тренировочном наборе данных ~ 60 тысяч примеров с референсной транскрипцией `text` (ground truth) и гипотезой каждой из моделей\n",
    " * В тестовом наборе данных ~ 20 тысяч примеров с гипотезами от каждой из моделей, но без референсной транскрипции (ее нужно предсказать)\n",
    " * Также доступен миллион референсных фраз из того же домена (запросы к ассистентам), но без предсказаний моделей\n",
    "\n",
    "Задача: улучшить распознавание речи с помощью:\n",
    " * агрегации транскрипций\n",
    " * выбора лучшей транскрипции\n",
    " * исправления ошибок в транскрипциях"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json(\"data/noisy_text_aggregation_train.jsonl\", lines=True)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1f1c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_LIST = [\"qnet\", \"w2v\", \"w2v_tts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269062f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in train_df.head(5).iterrows():\n",
    "    \n",
    "    labels = [\n",
    "        row[model] == row[\"text\"] for model in MODEL_LIST\n",
    "    ]\n",
    "        \n",
    "    row_df = (\n",
    "        train_df\n",
    "        .drop({\"task\", \"text\"}, axis=1)\n",
    "        .iloc[[i]]\n",
    "        .style.set_properties(\n",
    "            **{'background-color': '#aaffaa'},\n",
    "            subset=[model for model, label in zip(MODEL_LIST, labels) if label]\n",
    "        )\n",
    "        .set_properties(\n",
    "            **{'background-color': '#ffaaaa'}, \n",
    "            subset=[model for model, label in zip(MODEL_LIST, labels) if not label]\n",
    "        )\n",
    "        .set_properties(width=\"150px\")\n",
    "    )\n",
    "    ipd.display(row_df)\n",
    "    ipd.display(ipd.Audio(f\"data/audio/{row['task']}.wav\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d79bce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_json(\"data/noisy_text_aggregation_test.jsonl\", lines=True)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5978f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = pd.read_csv(\"data/noisy_text_aggregation_text_only.csv\", header=None)\n",
    "\n",
    "text_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207730f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hash_reminder(str_, base: int=10) -> int:\n",
    "    return int(hashlib.md5(str_.encode()).hexdigest(), 16) % base\n",
    "\n",
    "train_mask = train_df['task'].apply(lambda x: hash_reminder(x, 10) <= 7)\n",
    "\n",
    "val_df = train_df[~train_mask]\n",
    "train_df = train_df[train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f37da24",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8471d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathrm{L}(a, b) = \n",
    "\\begin{cases}\n",
    "    |a|,& \\text{if } |b| = 0, ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \\text{# second sequence is empty} \\\\\n",
    "    |b|,& \\text{if } |a| = 0, ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \\text{# first sequence is empty} \\\\\n",
    "    \\mathrm{L}(\\mathrm{tail}(a), \\mathrm{tail}(b)),& \\text{if } \\mathrm{head}(a) = \\mathrm{head}(b), ~ ~ \\text{# first elements of two sequencies are equal} \\\\\n",
    "    1 + min \n",
    "    \\begin{cases} \n",
    "        \\mathrm{L}(\\mathrm{tail}(a), b), ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \\text{# deletion from first sequence} \\\\ \n",
    "        \\mathrm{L}(a, \\mathrm{tail}(b)), ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ ~ \\text{# insertion into first sequence} \\\\ \n",
    "        \\mathrm{L}(\\mathrm{tail}(a), \\mathrm{tail}(b)); ~ ~ ~ ~ \\text{# substitution}\n",
    "    \\end{cases} & \\text{, otherwise.}\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14181a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(ref: Iterable, hyp: Iterable) -> int:\n",
    "    \"\"\"\n",
    "    dummy levenshtein implementation O(3^n)\n",
    "    \"\"\"\n",
    "    if not ref:\n",
    "        return len(hyp)\n",
    "    if not hyp:\n",
    "        return len(ref)\n",
    "    return min(\n",
    "        edit_distance(ref[1:], hyp[1:]) + (ref[0] != hyp[0]), # Correct / Insertion\n",
    "        edit_distance(ref, hyp[1:]) + 1, # Deletion\n",
    "        edit_distance(ref[1:], hyp) + 1 # Substitution\n",
    "    )\n",
    "\n",
    "\n",
    "def edit_distance(ref: Iterable, hyp: Iterable, plot: bool=False) -> int:\n",
    "    \"\"\"\n",
    "    dynamic programming levenshtein implementation O(n^2)\n",
    "    \"\"\"\n",
    "    \n",
    "    dist = np.zeros((len(hyp) + 1, len(ref) + 1), dtype=np.int32)\n",
    "    \n",
    "    dist[:, 0] = np.arange(len(hyp) + 1)\n",
    "    dist[0, :] = np.arange(len(ref) + 1)\n",
    "\n",
    "    for i, r in enumerate(hyp, start=1):\n",
    "        for j, h in enumerate(ref, start=1):\n",
    "            dist[i, j] = min(\n",
    "                dist[i - 1, j - 1] + (r != h),\n",
    "                dist[i, j - 1] + 1,\n",
    "                dist[i - 1, j] + 1\n",
    "            )\n",
    "    if plot:\n",
    "        sns.heatmap(\n",
    "            pd.DataFrame(\n",
    "                dist,\n",
    "                index=[' '] + list(hyp),\n",
    "                columns=[' '] + list(ref)\n",
    "            ),\n",
    "            annot=True,\n",
    "            cmap='coolwarm_r',\n",
    "            linewidth=2\n",
    "        )\n",
    "        plt.tick_params(\n",
    "            axis='both', which='major', labelsize=14, left=False, labelbottom=False, \n",
    "            bottom=False, top=False, labeltop=True\n",
    "        )\n",
    "        plt.yticks(rotation=0)\n",
    "            \n",
    "    return dist[-1, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb222326",
   "metadata": {},
   "outputs": [],
   "source": [
    "edit_distance('мама мыла раму', 'мама раму', plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcc7c05",
   "metadata": {},
   "source": [
    "* Подходит ли само по себе расстояние Левенштейна в качестве метрики? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e7e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_rate(refs: Iterable[Iterable], hyps: Iterable[Iterable]) -> float:\n",
    "    \"\"\"\n",
    "    ignoring hypotheses with empty references\n",
    "    \"\"\"\n",
    "    \n",
    "    wrong_words, all_words = 0, 0\n",
    "    \n",
    "    for ref, hyp in tqdm(zip(refs, hyps), total=len(refs)):\n",
    "        if len(ref) > 0:\n",
    "            wrong_words += edit_distance(ref, hyp)\n",
    "            all_words += len(ref)\n",
    "        else:\n",
    "            continue\n",
    "    return wrong_words / all_words\n",
    "\n",
    "\n",
    "def wer(refs: Iterable[str], hyps: Iterable[str]) -> float:\n",
    "    \"\"\"\n",
    "    Word Error Rate\n",
    "    \"\"\"\n",
    "    return error_rate(\n",
    "        [ref.split() for ref in refs],\n",
    "        [hyp.split() for hyp in hyps]\n",
    "    )\n",
    "\n",
    "\n",
    "def cer(refs: Iterable[str], hyps: Iterable[str]) -> float:\n",
    "    \"\"\"\n",
    "    Character Error Rate\n",
    "    \"\"\"\n",
    "    return error_rate(refs, hyps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915402ea",
   "metadata": {},
   "source": [
    "* Может ли Error Rate быть > 1 ?\n",
    "* Что дольше считать WER или CER ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92973ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "method2wer = {model: wer(val_df[model], val_df['text']) for model in MODEL_LIST}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fb8c50",
   "metadata": {},
   "source": [
    "# Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5237d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align(ref: Iterable, hyp: Iterable) -> List[Tuple[str, str, str]]:\n",
    "    \n",
    "    dist = np.zeros((len(hyp) + 1, len(ref) + 1), dtype=np.int32)\n",
    "    \n",
    "    dist[:, 0] = np.arange(len(hyp) + 1)\n",
    "    dist[0, :] = np.arange(len(ref) + 1)\n",
    "    \n",
    "    cache = [[None] * (len(ref) + 1) for _ in range(len(hyp) + 1)]\n",
    "    \n",
    "    for i, h in enumerate(hyp, start=1):\n",
    "        cache[i][0] = ('I', '%', h)\n",
    "    \n",
    "    for i, r in enumerate(ref, start=1):\n",
    "        cache[0][i] = ('D', r, '#')\n",
    "        \n",
    "    for i, h in enumerate(hyp, start=1):\n",
    "        for j, r in enumerate(ref, start=1):\n",
    "        \n",
    "            cases = []\n",
    "            \n",
    "            if r == h:\n",
    "                cases.append((\n",
    "                    dist[i - 1, j - 1],\n",
    "                    ('C', r, h)\n",
    "                ))\n",
    "            else:\n",
    "                cases.append((\n",
    "                    dist[i - 1, j - 1] + 1,\n",
    "                    ('S', r, h)\n",
    "                ))\n",
    "            cases.append((\n",
    "                dist[i, j - 1] + 1,\n",
    "                ('D', r, '#')\n",
    "            ))\n",
    "            cases.append((\n",
    "                dist[i - 1, j] + 1,\n",
    "                ('I', '%', h)\n",
    "            ))\n",
    "            \n",
    "            dist[i, j], cache[i][j] = min(cases, key=lambda x: x[0])\n",
    "            \n",
    "    alignment = []\n",
    "    i, j = len(hyp), len(ref)\n",
    "    \n",
    "    while i != 0 or j != 0:\n",
    "        action, r, h = cache[i][j]\n",
    "        alignment.append((action, r, h))\n",
    "        if action in {'C', 'S'}:\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif action == 'I':\n",
    "            i -= 1\n",
    "        else:\n",
    "            j -= 1\n",
    "\n",
    "    return alignment[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0eadbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "align('машинное обучение', 'мышиное облучение')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fac17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "align('мама мыла раму с мылом'.split(), 'мама мыла с млом'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab7ef6",
   "metadata": {},
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dffe94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from crowdkit.aggregation import ROVER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc14dff",
   "metadata": {},
   "source": [
    "**R**ecognizer **O**utput **V**oting **E**rror **R**eduction\n",
    "\n",
    "https://ieeexplore.ieee.org/document/659110\n",
    "\n",
    "https://arxiv.org/pdf/2107.01091.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2dab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rover_df(df: pd.DataFrame, model_cols: List[str], tmp_col: str=\"__tmp\") -> pd.DataFrame:\n",
    "\n",
    "    rover_df = df.copy()\n",
    "    \n",
    "    if \"text\" in rover_df.columns:\n",
    "        rover_df.drop(\"text\", axis=1, inplace=True)\n",
    "    \n",
    "    rover_df[tmp_col] = rover_df.apply(lambda row: [(model, row[model]) for model in model_cols], axis=1)\n",
    "    \n",
    "    rover_df = rover_df.drop(model_cols, axis=1).explode(tmp_col)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        \"task\": rover_df[\"task\"],\n",
    "        \"performer\": rover_df[tmp_col].apply(lambda x: x[0]),\n",
    "        \"text\": rover_df[tmp_col].apply(lambda x: x[1])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c39d8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_rover_df = get_rover_df(val_df, model_cols=MODEL_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b0159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rover_result = (\n",
    "    ROVER(\n",
    "        tokenizer=lambda x: list(x),\n",
    "        detokenizer=lambda s: \"\".join(s),\n",
    "        silent=False\n",
    "    )\n",
    "    .fit_predict(val_rover_df)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bded76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rover_result = pd.merge(\n",
    "    val_df,\n",
    "    rover_result.reset_index(),\n",
    "    on='task'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05615c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "method2wer['ROVER'] = wer(rover_result['agg_text'], rover_result['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a301cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "method2wer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d92463e",
   "metadata": {},
   "source": [
    "* Как можно улучшить ROVER ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ef1ade",
   "metadata": {},
   "source": [
    "# Error Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6154cb",
   "metadata": {},
   "source": [
    "https://norvig.com/spell-correct.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5126bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_edit_words(word: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    return list of candidates with one correction\n",
    "    \"\"\"\n",
    "    letters = 'абвгдежзийклмнопрстуфхцчшщъыьэюя'\n",
    "    splits = [(word[:i], word[i:]) for i in range(len(word) + 1)]\n",
    "    deletions = [left + right[1:] for left, right in splits if right]\n",
    "    substitutions = [left + c + right[1:] for left, right in splits if right for c in letters]\n",
    "    insertions = [left + c + right for left, right in splits for c in letters]\n",
    "    return set(deletions + substitutions + insertions)\n",
    "\n",
    "\n",
    "word_counts = Counter([word for utterance in train_df['text'].str.split() for word in utterance])\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def correct_word(word: str) -> str:\n",
    "    if word in word_counts:\n",
    "        return word\n",
    "    \n",
    "    candidates = one_edit_words(word)\n",
    "    \n",
    "    candidates = sorted([\n",
    "            (word, word_counts[word])\n",
    "            for word in candidates if word_counts[word] > 0\n",
    "        ],\n",
    "        key=lambda x: -x[1]\n",
    "    )\n",
    "    \n",
    "    if candidates:\n",
    "        return max(candidates, key=lambda x: x[1])[0]\n",
    "    return word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd24076",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_corrected = val_df['w2v'].apply(\n",
    "    lambda x: \" \".join([correct_word(w) for w in x.split()])\n",
    ")\n",
    "\n",
    "method2wer['w2v_corrected'] = wer(val_df['text'], w2v_corrected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abee71ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "method2wer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb0274d",
   "metadata": {},
   "source": [
    "# Rescoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788c95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceLanguageModel:\n",
    "    \n",
    "    def __init__(\n",
    "            self, \n",
    "            tokenized_texts: Iterable[Iterable[str]], \n",
    "            n: int, \n",
    "            delta: float = 0.0, \n",
    "            BOS: str='<BOS>',\n",
    "            EOS: str='<EOS>'\n",
    "        ):\n",
    "        self.n = n\n",
    "        self.BOS = BOS\n",
    "        self.EOS = EOS\n",
    "        ngram_counts: Dict[Tuple[str, ...], Dict[str, int]] = self.build_ngram_counts(\n",
    "            tokenized_texts, n, BOS, EOS\n",
    "        )\n",
    "        \n",
    "        self.vocab = {\n",
    "            token for distribution in ngram_counts.values() for token in distribution\n",
    "        }\n",
    "        \n",
    "        self.probs = defaultdict(Counter)\n",
    "\n",
    "        for prefix, distribution in ngram_counts.items():\n",
    "            norm: float = sum(distribution.values()) + delta * len(self.vocab)\n",
    "            self.probs[prefix] = {\n",
    "                token: (count + delta) / norm for token, count in distribution.items()\n",
    "            }\n",
    "            \n",
    "    @staticmethod\n",
    "    def build_ngram_counts(\n",
    "        tokenized_texts: Iterable[Iterable[str]], \n",
    "        n: int,\n",
    "        BOS: str,\n",
    "        EOS: str\n",
    "    ) -> Dict[Tuple[str, ...], Dict[str, int]]:\n",
    "        \n",
    "        counts = defaultdict(Counter)\n",
    "\n",
    "        for text in tokenized_texts:\n",
    "\n",
    "            ngrams = nltk.ngrams(\n",
    "                text, n=n, pad_left=True, pad_right=True, left_pad_symbol=BOS, right_pad_symbol=EOS\n",
    "            )\n",
    "\n",
    "            for ngram in ngrams:\n",
    "                prev, token = ngram[:-1], ngram[-1]\n",
    "                counts[prev][token] += 1\n",
    "\n",
    "        return counts\n",
    "    \n",
    "    \n",
    "    def __get_observed_token_distribution(self, prefix: List[str]) -> Dict[str, float]:\n",
    "        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n",
    "        prefix = [self.BOS] * (self.n - 1 - len(prefix)) + prefix\n",
    "        return self.probs[tuple(prefix)]\n",
    "    \n",
    "    \n",
    "    def get_token_distribution(self, prefix: List[str]) -> Dict[str, float]:\n",
    "        \n",
    "        distribution: Dict[str, float] = self.__get_observed_token_distribution(prefix)\n",
    "        \n",
    "        missing_prob_total: float = 1.0 - sum(distribution.values())\n",
    "        \n",
    "        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(distribution))\n",
    "        \n",
    "        return {token: distribution.get(token, missing_prob) for token in self.vocab}\n",
    "    \n",
    "    \n",
    "    def get_next_token_prob(self, prefix: List[str], next_token: str):\n",
    "        \n",
    "        distribution: Dict[str, float] = self.__get_observed_token_distribution(prefix)\n",
    "        \n",
    "        if next_token in distribution:\n",
    "            return distribution[next_token]\n",
    "        \n",
    "        else:\n",
    "            missing_prob_total = 1.0 - sum(distribution.values())\n",
    "            return max(0, missing_prob_total) / max(1, len(self.vocab) - len(distribution))\n",
    "    \n",
    "    \n",
    "    def score_sequence(self, tokens: List[str], min_logprob: float = np.log(10 ** -50.)) -> float:\n",
    "        prefix = [self.BOS] * (self.n - 1)\n",
    "        padded_tokens = tokens + [self.EOS]\n",
    "        logprobs_sum = 0.0\n",
    "        for token in padded_tokens:\n",
    "            logprob = np.log(self.get_next_token_prob(prefix, token))\n",
    "            prefix = prefix[1:] + [token]\n",
    "            logprobs_sum += max(logprob, min_logprob)\n",
    "        return logprobs_sum / len(tokens) if tokens else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm = LaplaceLanguageModel(\n",
    "    n=2,\n",
    "    tokenized_texts=text_data[0],\n",
    "    delta=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779cfe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in ('мама мыла раму', 'мамо мыла раму', 'машинное обучение', 'маинное обучение'):\n",
    "    score = lm.score_sequence(list(text))\n",
    "    print(f\"{text}\\t\\t{score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c593b2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_likelihood_utterances = val_df.apply(\n",
    "    lambda row: row[\n",
    "        np.array([\n",
    "            lm.score_sequence(tokens=list(row[model])) for model in MODEL_LIST\n",
    "        ]).argmax()\n",
    "    ], \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcfca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "method2wer['dummy_rescoring'] = wer(val_df['text'], max_likelihood_utterances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05137f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "method2wer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbeba7f",
   "metadata": {},
   "source": [
    "# Oracle WER\n",
    "\n",
    "если представить, что мы идеально выбираем лучшую из трех гипотез (Оракул), каким будет Word Error Rate?\\\n",
    "таким образом оценим нижнюю границу Rescoring-системы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea40175",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_transcription(ref: Iterable[str], hyps: Iterable[Iterable[str]]):\n",
    "    return hyps[\n",
    "        np.array([\n",
    "            edit_distance(ref, hyp) for hyp in hyps\n",
    "        ]).argmin()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa6170d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oracle_hyp = val_df.apply(\n",
    "    lambda row: \" \".join(\n",
    "        get_best_transcription(\n",
    "            ref=row['text'].split(),\n",
    "            hyps=[row[model].split() for model in MODEL_LIST]\n",
    "        )\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1166a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "method2wer['oracle_wer'] = wer(val_df['text'], oracle_hyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d42bbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "method2wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ec917",
   "metadata": {},
   "outputs": [],
   "source": [
    "{'qnet': 0.7652783922138658,\n",
    " 'w2v': 0.5601030720835285,\n",
    " 'w2v_tts': 0.620017745017745,\n",
    " 'ROVER': 0.5634646316005613,\n",
    " 'w2v_corrected': 0.5412983965584669,\n",
    " 'dummy_rescoring': 0.6509581540868205,\n",
    " 'oracle_wer': 0.49483770043019165}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d9b785",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed278b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rover_df = get_rover_df(test_df, model_cols=MODEL_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fd1777",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = (\n",
    "    ROVER(\n",
    "        tokenizer=lambda x: list(x),\n",
    "        detokenizer=lambda s: \"\".join(s),\n",
    "        silent=False\n",
    "    )\n",
    "    .fit_predict(test_rover_df)\n",
    "    .reset_index()\n",
    "    .rename({'agg_text': 'prediction'}, axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f53db",
   "metadata": {},
   "outputs": [],
   "source": [
    "username = \n",
    "\n",
    "test_result.to_json(\n",
    "    f\"noisy_text_aggregation_test_prediction_{username}.jsonl\",\n",
    "    lines=True, orient=\"records\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e462af93",
   "metadata": {},
   "source": [
    "# TODO\n",
    "\n",
    "* провести эксперименты с разными подходами\n",
    "* аккуратно валидироваться и тестироваться\n",
    "* сформировать файл с предсказаниями\n",
    "* <font color='red'>в переменную `username` указать фамилию <font> \n",
    "* прикрепить на портале jupyter-notebook / .py-file / colab-link и файл с предсказаниями"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a47d7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
